{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5\n",
    "\n",
    "We have now covered the perceptron, Adaline, and logistic regression.\n",
    "\n",
    "When using gradient descent, the only difference between these algorithms is how $\\hat{y}$ is computed.\n",
    "\n",
    "In this file create one method called `fit_linear()` that takes as a parameter a value called `algorithm`.\n",
    "\n",
    "If `algorithm=\"perceptron\"` then `fit_linear()` fits the data with a perceptron.\n",
    "\n",
    "If `algorithm=\"adaline\"` then `fit_linear()` fits the data with Adaline.\n",
    "\n",
    "If `algorithm=\"logreg\"` then `fit_linear()` fits the data with logistic regression.\n",
    "\n",
    "The default value of `algorithm` is `logreg`. \n",
    "\n",
    "The `fit_linear` can use batch, stochastic, or mini-batch gradient descent (your choice). \n",
    "\n",
    "You do not have to implement all 3. \n",
    "\n",
    "### Task\n",
    "\n",
    "Once you have the method written, load the [Raisin](https://archive.ics.uci.edu/ml/datasets/Raisin+Dataset) dataset provided in this folder.\n",
    "\n",
    "Produce `X` and `y` as usual and use `sklearn` to do a train-test split and scale the data.\n",
    "\n",
    "Then fit a linear model to the training set and check your accuracy on the test set.\n",
    "\n",
    "Which of the three algorithms performs best?\n",
    "\n",
    "### Extra credit\n",
    "\n",
    "If you are feeling ambitious, you can add regularization to your model, and a hyperparameter to control it.\n",
    "\n",
    "This is not as hard as it sounds.  \n",
    "\n",
    "Probably a properly tuned model with regularization will beat all three of the unregularized linear models. \n",
    "\n",
    "This extra credit is worth five points on the midterm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax = MinMaxScaler()\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda z: 1/(1+np.exp(-z))\n",
    "def Jgrad(X,y,w):\n",
    "\n",
    "    yhat = (X@w)\n",
    "    difference = (y-yhat).reshape(X.shape[0],1)\n",
    "    return np.sum(difference*(X),axis=0)/X.shape[0]\n",
    "def Jgrad2(X,y,w):\n",
    "    sigmoid = lambda z: 1/(1+np.exp(-z))\n",
    "    yhat = sigmoid(X@w)\n",
    "    difference = (y-yhat).reshape(X.shape[0],1)\n",
    "    return np.sum(difference*(X),axis=0)/X.shape[0]\n",
    "\n",
    "\n",
    "def fit_adeline_simple(X,y,max_epochs=100,eta=0.1):\n",
    "\n",
    "    w = np.random.randn(X.shape[1])/10\n",
    "    for epoch in range(max_epochs):\n",
    "        w += eta*Jgrad(X,y,w)\n",
    "    return w\n",
    "\n",
    "def fit_logreg_simple(X,y,max_epochs=100,eta=0.1):\n",
    "\n",
    "    w = np.random.randn(X.shape[1])/10\n",
    "    for epoch in range(max_epochs):\n",
    "        w += eta*Jgrad2(X,y,w)\n",
    "    return w\n",
    "\n",
    "def fit_perceptron_simple(X,y,max_epochs=100,eta=0.1):\n",
    "    w = np.random.randn(X.shape[1])/10\n",
    "    for epoch in range(max_epochs):\n",
    "        for x,y_i in zip(X,y):\n",
    "            yhat = phi(w.T@x)\n",
    "            dw_0 = eta*(y_i-yhat)*x\n",
    "            w += dw_0\n",
    "        return w\n",
    "   \n",
    "\n",
    "\n",
    "def fit_linear(X,y,algorithm = 'logreg'):\n",
    "    if algorithm == 'adaline':\n",
    "        return fit_adeline_simple(X,y)\n",
    "    elif algorithm == 'logreg':\n",
    "        return fit_logreg_simple(X,y)\n",
    "    elif algorithm == 'perceptron' :\n",
    "        return fit_perceptron_simple(X,y)\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933071490757153"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87524</td>\n",
       "      <td>442.246011</td>\n",
       "      <td>253.291155</td>\n",
       "      <td>0.819738</td>\n",
       "      <td>90546</td>\n",
       "      <td>0.758651</td>\n",
       "      <td>1184.040</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75166</td>\n",
       "      <td>406.690687</td>\n",
       "      <td>243.032436</td>\n",
       "      <td>0.801805</td>\n",
       "      <td>78789</td>\n",
       "      <td>0.684130</td>\n",
       "      <td>1121.786</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90856</td>\n",
       "      <td>442.267048</td>\n",
       "      <td>266.328318</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>93717</td>\n",
       "      <td>0.637613</td>\n",
       "      <td>1208.575</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45928</td>\n",
       "      <td>286.540559</td>\n",
       "      <td>208.760042</td>\n",
       "      <td>0.684989</td>\n",
       "      <td>47336</td>\n",
       "      <td>0.699599</td>\n",
       "      <td>844.162</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79408</td>\n",
       "      <td>352.190770</td>\n",
       "      <td>290.827533</td>\n",
       "      <td>0.564011</td>\n",
       "      <td>81463</td>\n",
       "      <td>0.792772</td>\n",
       "      <td>1073.251</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0  87524       442.246011       253.291155      0.819738       90546   \n",
       "1  75166       406.690687       243.032436      0.801805       78789   \n",
       "2  90856       442.267048       266.328318      0.798354       93717   \n",
       "3  45928       286.540559       208.760042      0.684989       47336   \n",
       "4  79408       352.190770       290.827533      0.564011       81463   \n",
       "\n",
       "     Extent  Perimeter    Class  \n",
       "0  0.758651   1184.040  Kecimen  \n",
       "1  0.684130   1121.786  Kecimen  \n",
       "2  0.637613   1208.575  Kecimen  \n",
       "3  0.699599    844.162  Kecimen  \n",
       "4  0.792772   1073.251  Kecimen  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Raisin_Dataset/Raisin_Dataset.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] = df.Class.apply(lambda x: 1 if x =='Kecimen' else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'Class')\n",
    "y = df['Class'].to_numpy()\n",
    "X = minmax.fit_transform(X)\n",
    "X = np.c_[np.ones(X.shape[0]),X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4061814 , -0.47342129, -0.7400664 , -0.29348748, -0.0990526 ,\n",
       "       -0.71685375,  0.53726238, -0.45238527])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi = lambda z: (z >= 0)*2 -1\n",
    "w = fit_linear(X_train,y_train,'adaline')\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8513888888888889, 0.8611111111111112)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = phi(X_train@w)\n",
    "y_pred_test = phi(X_test@w)\n",
    "accuracy_train = accuracy_score(y_train,y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test,y_pred_test)\n",
    "accuracy_train,accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w = fit_linear(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(arr):\n",
    "    arr[arr <.5] = -1\n",
    "    arr[arr>= .5] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49583333333333335, 0.5166666666666667)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = sigmoid(X_train@w)\n",
    "classify(y_pred_train)\n",
    "y_pred_test = sigmoid(X_test@w)\n",
    "classify(y_pred_test)\n",
    "accuracy_train = accuracy_score(y_train,y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test,y_pred_test)\n",
    "accuracy_train,accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65678759, -0.45951874, -0.89760257, -0.11879451, -0.64286921,\n",
       "       -0.45240104,  0.68416628, -0.71954525])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi = lambda z: (z >= 0)*2 -1\n",
    "w = fit_linear(X_train,y_train,'perceptron')\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8722222222222222, 0.8666666666666667)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = phi(X_train@w)\n",
    "y_pred_test = phi(X_test@w)\n",
    "accuracy_train = accuracy_score(y_train,y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test,y_pred_test)\n",
    "accuracy_train,accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "## Adaline did a bit better than perceptron. logistic regression did poorly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
